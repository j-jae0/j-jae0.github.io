---
title:  "[ML] ì‚¬ì´í‚·ëŸ°(scikit-learn)ìœ¼ë¡œ ë³´ìŠ¤í„´ ì§‘ê°’ ì˜ˆì¸¡í•˜ê¸° - ë‹¤í•­ íšŒê·€(Polynomial Regression)"
layout: single

categories: "ML"
tags: ["ë‹¤í•­íšŒê·€", "ì‚¬ì´í‚·ëŸ°"]

toc: true
toc_sticky: true
toc_label : "ëª©ì°¨"
toc_icon: "bars"
---

<small>ì‚¬ì´í‚·ëŸ°ì˜ ë³´ìŠ¤í„´ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤í•­ íšŒê·€ ë¶„ì„ì„ í•œë‹¤. ì°¸ê³ ë¡œ í•´ë‹¹ ë°ì´í„°ì…‹ì€ ìœ¤ë¦¬ì ì¸ ë¬¸ì œë¡œ scikit-learn 1.2 ë²„ì „ ì´í›„ë¡œ ì‚­ì œë˜ì—ˆë‹¤.</small>

***


# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ë°ì´í„° ë¡œë“œ
```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.datasets import load_boston
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import pandas as pd  

# ë³´ìŠ¤í„´ ë°ì´í„°ì…‹ì„ boston_dataset ë³€ìˆ˜ì— ì €ì¥
boston = load_boston()
```

<br>

# 2. ë³€ìˆ˜ ìƒì„± ë° í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„° ë‚˜ëˆ„ê¸°
ê°€ì„¤í•¨ìˆ˜ë¥¼ 2ì°¨ í•¨ìˆ˜ë¼ê³  ê°€ì •í•˜ê³ , ê·¸ì— ë§ëŠ” ë³€ìˆ˜ë“¤ì„ ìƒì„±í•´ì•¼í•œë‹¤. ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

```python
# ë‹¤í•­ íšŒê·€, ê°€ì„¤í•¨ìˆ˜ë¥¼ 2ì°¨ í•¨ìˆ˜ë¡œ ì„¤ì •
polynomial_transformer = PolynomialFeatures(2)
# 2ì°¨ í•¨ìˆ˜ì— ë§ê²Œ ë³€ìˆ˜ ìƒì„± 
polynomial_data = polynomial_transformer.fit_transform(boston.data)
# ìƒì„±ëœ ë³€ìˆ˜ì—ë„ ë³€ìˆ˜ëª…ì„ ë¶€ì—¬
polynomial_feature_names = polynomial_transformer.get_feature_names(boston.feature_names)

# x, y ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ ë³€í™˜
x = pd.DataFrame(polynomial_data, columns=polynomial_feature_names)
y = pd.DataFrame(boston.target, columns=[['MEDV']])
```

x shape : ```(506, 105)```, y shape : ```(506, 1)```

```python
# í•™ìŠµ, í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ë‚˜ëˆ„ê¸°
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
```

í•™ìŠµ ë°ì´í„°ì…‹ì€ 80%, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì€ 20%ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê³  ```random_state```ë¥¼ 42ë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„° ë¶„ë°° ê²°ê³¼ë¥¼ ê³ ì •í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.

```python
# ì˜ ë‚˜ëˆ„ì–´ì¡ŒëŠ”ì§€ shapeë¡œ í™•ì¸
print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)
```
```
ì¶œë ¥ ê²°ê³¼
(404, 105) (102, 105) (404, 1) (102, 1)
```

<br>

# 3. ëª¨ë¸ë§, í‰ê°€
```python
# ì„ í˜• íšŒê·€ í•¨ìˆ˜ ì‚¬ìš©
model = LinearRegression()
# í•™ìŠµë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
model.fit(x_train, y_train)
# í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì— í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì…ë ¥í•˜ì—¬ yê°’ì„ ì˜ˆì¸¡
y_predict = model.predict(x_test)

# RMSE ê°’ êµ¬í•˜ê¸°
mean_squared_error(y_test, y_test_prediction) ** 0.5
```
```
ì¶œë ¥ ê²°ê³¼
3.7661065104015696
```

ë³´ìŠ¤í„´ ì£¼íƒ ê°€ê²© ë°ì´í„°ì…‹ì„ í•™ìŠµ, í…ŒìŠ¤íŠ¸ 8:2ë¡œ ë°ì´í„°ë¥¼ ë‚˜ëˆ„ê³  ë‹¤ì¤‘ íšŒê·€(ê°€ì„¤í•¨ìˆ˜ 2ì°¨ í•¨ìˆ˜ë¡œ ê°€ì •)ë¡œ ë¶„ì„í•œ ê²°ê³¼ ì•½ 3.8 ì •ë„ì˜ ì˜¤ì°¨ë¥¼ ê°€ì§€ëŠ” ëª¨ë¸ì„ ìƒì„±í•˜ì˜€ë‹¤. ì´ì „ì— ë²”ì£„ìœ¨ë§Œ ê°€ì§€ê³  ì£¼íƒ ê°€ê²©ì„ ì˜ˆì¸¡í–ˆì„ ë•Œ(RMSE : ì•½ 7.8)ì™€ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì „ì²´ ë‹¤ ì‚¬ìš©í–ˆìœ¼ë‚˜ ì„ í˜•ìœ¼ë¡œ ì˜ˆì¸¡í•œ ë‹¤ì¤‘ì„ í˜•íšŒê·€(RMSE : ì•½ 4.9) ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•„ì¡ŒìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.

<br>

# 4. ìµœì¢… ëª¨ë¸

```python
# theta 0ì˜ ê°’
model.intercept_
# theta 1, 2, 3 ... ì˜ ê°’
model.coef_
```
**theta 0ì˜ ê°’** :
```
array([4.92670721e+08])
```
**theta 1, 2, 3, ..., 13ì˜ ê°’** : 
```
array([[-4.92670936e+08, -7.22931535e+00,  6.64177060e-01,
        -4.72179590e+00,  3.67378882e+01,  2.85261009e+02,
         1.78393390e+01,  6.64572881e-01, -4.11341040e+00,
         2.66263484e+00, -8.43232394e-03,  7.64945359e+00,
         1.32201393e-01, -2.02052871e-01,  3.52764521e-04,
         7.38855141e-02,  5.84418414e-01,  2.58757422e+00,
        -2.02837847e+00,  1.75603439e-01, -5.40745692e-03,
        -1.89117490e-01,  2.71314302e-01, -3.52477416e-02,
         6.94397406e-01, -4.79466963e-04,  3.38903866e-02,
        -5.10155901e-04, -4.63119868e-03, -6.28083514e-02,
        -1.37674876e+00, -3.78123454e-03,  1.24102968e-03,
        -2.13795684e-02, -1.92521604e-02,  8.57218385e-04,
        -4.51568792e-03,  1.80318307e-04, -9.46247722e-03,
         5.45338803e-02, -1.02797894e-02, -2.15994391e-01,
         3.06860323e-01,  4.88014045e-03,  1.65323538e-01,
        -1.00727368e-03, -5.39816702e-04, -2.70282025e-02,
         4.05514997e-03, -1.83414642e-02,  3.67378833e+01,
        -3.67209648e+01, -5.26529847e+00, -3.03016356e-02,
        -9.23229861e-01,  1.28146102e-01, -9.10391216e-03,
        -8.38122909e-01,  1.11381162e-02, -2.41896558e-01,
        -9.84147266e+01, -8.70543217e+00, -4.60198145e-02,
         1.48030219e+01, -2.07999870e+00,  2.84684335e-01,
        -1.44996628e+01,  1.70896337e-03,  1.01429845e+00,
         1.13033641e+00, -6.77317315e-02, -3.26822751e-01,
        -1.83631659e-01, -1.24709743e-02, -5.64945789e-01,
        -6.57185143e-03, -3.68862299e-02, -1.49994397e-05,
         3.74969342e-04,  1.42119169e-02, -4.84839890e-04,
         4.45775932e-03, -6.50274375e-04, -8.34292370e-03,
         5.03210046e-01,  7.43943729e-02, -6.13610785e-03,
        -2.56856051e-01, -4.21354965e-03,  3.94347786e-02,
        -8.29077422e-02,  4.97195607e-03, -1.69892466e-01,
         4.15677692e-03, -2.95959896e-02, -4.70479767e-05,
         9.39935703e-03, -4.29702479e-04, -1.13419291e-03,
        -2.59300486e-02,  5.94455365e-03,  2.60203089e-02,
        -4.28552296e-05, -3.08363345e-04,  1.67517301e-02]])
```

ì´ë²ˆ ê²°ê³¼ëŠ” ì´ì „ì— ë¶„ì„í•œ ê²°ê³¼(ì…ë ¥ê°’ì´ 1ê°œ)ì™€ëŠ” ë‹¤ë¥´ê²Œ ì…ë ¥ë³€ìˆ˜ê°€ 13ê°œì´ê¸° ë•Œë¬¸ì— ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê¸° ì–´ë µë‹¤. í•˜ì§€ë§Œ ë‹¤í•­ íšŒê·€ ëª¨ë¸ì˜ ì„¸íƒ€ê°’ë“¤ì€ ìœ„ì™€ ê°™ì´ êµ¬í•  ìˆ˜ ìˆì—ˆë‹¤.

<br>

# 6. Reference
- [scikit-learn ê³µì‹ ë¬¸ì„œ, ë³´ìŠ¤í„´ ë°ì´í„°ì…‹](https://scikit-learn.org/0.15/modules/generated/sklearn.datasets.load_boston.html)

<br>

ğŸ‘©ğŸ»â€ğŸ’»ê°œì¸ ê³µë¶€ ê¸°ë¡ìš© ë¸”ë¡œê·¸ì…ë‹ˆë‹¤
<br>ì˜¤ë¥˜ë‚˜ í‹€ë¦° ë¶€ë¶„ì´ ìˆì„ ê²½ìš° ëŒ“ê¸€ í˜¹ì€ ë©”ì¼ë¡œ ë”°ë”í•˜ê²Œ ì§€ì í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤.
{: .notice}